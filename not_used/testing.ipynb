{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%reset -f",
   "id": "33c2da8da1fa6033",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import scipy.io\n",
    "import Rbeast as rb\n",
    "from SLM_tools import *\n",
    "from scipy.io import savemat\n",
    "import pickle\n",
    "import re\n",
    "import time"
   ],
   "id": "b288aa08260ce060",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_dir = r\"C:\\Users\\User\\OneDrive - mail.tau.ac.il\\Documents\\Final Project\\Project2-Omri and Idan\\Results\" \n",
    "\n",
    "pattern = re.compile(\n",
    "    r\"(?P<type>distance|energy)_vec_mu_(?P<mu>[-+]?\\d*\\.\\d+|\\d+)_energy_(?P<energy>[-+]?\\d*\\.\\d+|\\d+)_run_num_(?P<run_num>\\d+)_total_num_target_\\d+\\.mat\"\n",
    ")\n",
    "\n",
    "distance_paths = []\n",
    "energy_paths = []\n",
    "seen_distance_paths = set()\n",
    "seen_energy_paths = set()\n",
    "mu = 1.6\n",
    "for root, dirs, files in os.walk(top_dir):\n",
    "    for file in files:\n",
    "        match = pattern.match(file)\n",
    "        if match:\n",
    "            file_info = match.groupdict()\n",
    "            if file_info['mu'] == str(mu):\n",
    "                full_path = os.path.join(root, file)\n",
    "                if file_info['type'] == 'distance':\n",
    "                    if full_path not in seen_distance_paths:\n",
    "                        distance_paths.append(full_path)\n",
    "                        seen_distance_paths.add(full_path)\n",
    "                elif file_info['type'] == 'energy':\n",
    "                    if full_path not in seen_energy_paths:\n",
    "                        energy_paths.append(full_path)\n",
    "                        seen_energy_paths.add(full_path)\n"
   ],
   "id": "1e8eb91d074f320",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "C = []\n",
    "downsampling_factor = 1000\n",
    "n_components = 3\n",
    "features_extracted = 0\n",
    "total_runtime = 0\n",
    "files_with_assembly = 0\n",
    "total_data_files = len(distance_paths)\n",
    "log = []\n",
    "mu = 1.6\n",
    "counters = {\"load\":[],\"extraction\":[],\"segmentation\":[],\"pca\":None,\"extracted_features\":[]}\n",
    "for i, (energy_path, distance_path) in enumerate(zip(energy_paths, distance_paths)):\n",
    "    start1 = time.time()\n",
    "    distance_data = scipy.io.loadmat(distance_path)['foo']\n",
    "    energy_data = scipy.io.loadmat(energy_path)['foo'].T\n",
    "    energy_data, distance_data, time_vec = SLM_tools.downsample(energy_data, distance_data,downsampling_factor)\n",
    "    loading_time = round(time.time() - start1,3)\n",
    "    log1 = f\"\\nfile {i+1}/{len(energy_paths)}  loaded: {os.path.relpath(energy_path,top_dir)} Loading time: {loading_time} seconds\"\n",
    "    print(log1)\n",
    "    log.append(log1)\n",
    "    counters[\"load\"].append(loading_time)\n",
    "    start2 = time.time()\n",
    "    o, cp, mean_trend = SLM_tools.beast(energy_data)\n",
    "    segmentation_time = round(time.time() - start2,3)\n",
    "    log2 = f\"\\nfinished segmentation(Beast), runtime: {segmentation_time} seconds\"\n",
    "    print(log2)\n",
    "    log.append(log2)\n",
    "    counters[\"segmentation\"].append(segmentation_time)\n",
    "    start3 = time.time()\n",
    "    A = SLM_tools.segment_data(energy_data, distance_data,mean_trend,cp)\n",
    "    extraction_time = round(time.time() - start3,3)\n",
    "    print(f\"\\nfinished feature extraction, runtime: {extraction_time} seconds\")\n",
    "    counters[\"extraction\"].append(extraction_time)\n",
    "    print(f\"\\nAssembly? : {len(A) > 0}\")\n",
    "    if len(A) > 0:\n",
    "        files_with_assembly += 1\n",
    "        features_extracted += A[0].shape[0]\n",
    "        counters[\"extracted_features\"].append(A[0].shape[0])\n",
    "        log3 = f\"\\nfiles_with_assembly: {files_with_assembly}/{total_data_files}\"\n",
    "        print(log3)\n",
    "        log.append(log3)\n",
    "        log4 = f\"\\nTotal features_extracted: {features_extracted}\"\n",
    "        print(log4)\n",
    "        log.append(log4)\n",
    "    else:\n",
    "        log5 = f\"\\nNo Assembly, No features extracted\"\n",
    "        print(log5)\n",
    "        log.append(log5)\n",
    "    C.append(A)\n",
    "    total_runtime += (loading_time + extraction_time + segmentation_time)\n",
    "log6 = f\"\\nFinished pre-pca processing,total runtime {total_runtime} for {len(energy_paths)} files\"\n",
    "print(log6)\n",
    "log.append(log6)\n",
    "with open(f\"C_all_mu_{mu}_v2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(C, f)\n",
    "log7 = \"\\nsaved all processed data\"\n",
    "print(log7)\n",
    "log.append(log7)\n",
    "start_pca = time.time()\n",
    "log8 = f\"\\nStarting PCA\"\n",
    "print(log8)\n",
    "log.append(log8)\n",
    "c_reduced = SLM_tools.post_beast_processing(C)\n",
    "principal_components, score, latent = SLM_tools.pca(c_reduced,n_components)\n",
    "a_reduced = SLM_tools.post_pca_processing(score, c_reduced,n_components)\n",
    "counters[\"selected_features\"] = a_reduced.shape[0]\n",
    "runtime_pca = round(time.time() - start_pca,3)\n",
    "counters[\"pca\"] = runtime_pca\n",
    "total_runtime += runtime_pca\n",
    "log9 = f\"\\nFinished PCA runtime {runtime_pca} seconds\"\n",
    "print(log9)\n",
    "log.append(log9)\n",
    "savemat(f\"a_reduced_all_mu_{mu}_v2.mat\", {'a_reduced': a_reduced})\n",
    "log10 = f\"\\nsaved all extracted features , total extracted features {features_extracted} total runtime {total_runtime} seconds\"\n",
    "log.append(log10)\n",
    "log.append(\"SUMMARY\")\n",
    "log11 = f\"\\nfiles {total_data_files} \\nfiles_with_assembly: {files_with_assembly}/{total_data_files} \\nmean extracted features {np.mean(counters['extracted_features'])} \\ntotal extracted features {features_extracted} \\ntotal_selected_features {counters['selected_features']} \\ntotal runtime {total_runtime} seconds \\nmean loading time {np.mean(counters['load'])} \\nmean segmentation time {np.mean(counters['segmentation'])} \\nmean extraction time {np.mean(counters['extraction'])} \\nPCA time {counters['pca']}\"\n",
    "log.append(log11)\n",
    "print(log11)\n",
    "with open(f\"run_log_27_7_mu_{mu}_v2.txt\",'w') as f:\n",
    "    for line in log:\n",
    "        f.write(line)"
   ],
   "id": "cca3f3fdb52ac460",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import scipy.io\n",
    "import Rbeast as rb\n",
    "from SLM_tools import *\n",
    "from scipy.io import savemat\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "%matplotlib inline"
   ],
   "id": "17d24917441d528",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "a_reduced = sio.loadmat(r\"C:\\Users\\User\\OneDrive - mail.tau.ac.il\\Documents\\SA_UI\\not_used\\a_reduced_all_mu_1.6_v2.mat\")[\"a_reduced\"]",
   "id": "84c65809e91ac80d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "a_reduced.shape",
   "id": "3e6c74da032e5978",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "YI, tfas_predict_mat, tfas_actually_mat, mean_error_mat, train_index, random_x, validation_index = SLM_tools.model_training_with_cv(a_reduced,n_components=3,cv_num=10,twoD_output=False)",
   "id": "a52c6ab53bbf5480",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "YI.shape",
   "id": "6ddfd83a00db75b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sio.savemat(\"YI_mu_1.6_2components.mat\", {'YI': YI})",
   "id": "553e9b374e21087b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sio.savemat(\"tfas_predict_mat_mu_1.6_3components_new_v2.mat\", {'tfas_predict_mat': tfas_predict_mat})\n",
    "sio.savemat(\"tfas_actually_mat_mu_1.6_3components_new_v2.mat\", {'tfas_actually_mat': tfas_actually_mat})\n",
    "sio.savemat(\"random_x_mu_1.6_3components_new_v2.mat\", {'random_x': random_x})\n",
    "sio.savemat(\"validation_index_mu_1.6_3components_new_v2.mat\", {'validation_index': validation_index})"
   ],
   "id": "efc3718406fd2e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tfas_predict_mat = sio.loadmat(r\"C:\\Users\\User\\OneDrive - mail.tau.ac.il\\Documents\\SA_UI\\not_used\\tfas_predict_mat_mu_1.6_3components_new_v2.mat\")[\"tfas_predict_mat\"]\n",
    "tfas_actually_mat = sio.loadmat(r\"C:\\Users\\User\\OneDrive - mail.tau.ac.il\\Documents\\SA_UI\\not_used\\tfas_actually_mat_mu_1.6_3components_new_v2.mat\")[\"tfas_actually_mat\"]"
   ],
   "id": "46a0609f0ef7151c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "path=r\"C:\\Users\\User\\OneDrive - mail.tau.ac.il\\Documents\\SA_UI\\not_used\"\n",
    "cv_num = 10\n",
    "mean_vec, std_vec, hist_space, x_hist_space, x_ticks, y_ticks, bin_width= SLM_tools.model_eval(tfas_predict_mat, tfas_actually_mat, cv_num, path)"
   ],
   "id": "1f573e1bcbaf88e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sio.savemat(\"mean_vec_mu_1.6_3components_new_v2.mat\", {'mean_vec': mean_vec})\n",
    "sio.savemat(\"std_vec_mu_1.6_3components_new_v2.mat\", {'std_vec': std_vec})\n",
    "sio.savemat(\"hist_space_mu_1.6_3components_new_v2.mat\", {'hist_space': hist_space})\n",
    "sio.savemat(\"x_hist_space_mu_1.6_3components_new_v2.mat\", {'x_hist_space': x_hist_space})\n",
    "sio.savemat(\"x_ticks_mu_1.6_3components_new_v2.mat\", {'x_ticks': x_ticks})\n",
    "sio.savemat(\"y_ticks_mu_1.6_3components_new_v2.mat\", {'y_ticks': y_ticks})"
   ],
   "id": "6c6ec63f0d12e251",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "a_reduced = sio.loadmat(r\"C:\\Users\\User\\OneDrive - mail.tau.ac.il\\Documents\\SA_UI\\not_used\\a_reduced_all_mu_1.6_v2.mat\")[\"a_reduced\"]",
   "id": "6fb5fa10483299c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tfas_predict_mat_2, tfas_actually_mat_2, mean_error_mat_2 = SLM_tools.train_again_on_validation_and_test(a_reduced, n_components=3)",
   "id": "b0fcdfb79b6312ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sio.savemat(\"tfas_predict_mat_2_mu_1.6_3components_new_v2.mat\", {'tfas_predict_mat_2': tfas_predict_mat_2})\n",
    "sio.savemat(\"tfas_actually_mat_2_mu_1.6_3components_new_v2.mat\", {'tfas_actually_mat_2': tfas_actually_mat_2})"
   ],
   "id": "96ae30ba41e6cf20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tfas_predict_mat_2.shape",
   "id": "a21e19d37177c1c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import scipy.io\n",
    "import Rbeast as rb\n",
    "from SLM_tools import *\n",
    "from scipy.io import savemat\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "%matplotlib inline"
   ],
   "id": "e688725d60a9434e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tfas_predict_mat_2 = sio.loadmat(r\"C:\\Users\\User\\OneDrive - mail.tau.ac.il\\Documents\\SA_UI\\not_used\\tfas_predict_mat_2_mu_1.6_3components_new_v2.mat\")[\"tfas_predict_mat_2\"]\n",
    "tfas_actually_mat_2 = sio.loadmat(r\"C:\\Users\\User\\OneDrive - mail.tau.ac.il\\Documents\\SA_UI\\not_used\\tfas_actually_mat_2_mu_1.6_3components_new_v2.mat\")[\"tfas_actually_mat_2\"]\n",
    "mean_vec = sio.loadmat(r\"C:\\Users\\User\\OneDrive - mail.tau.ac.il\\Documents\\SA_UI\\not_used\\mean_vec_mu_1.6_3components_new_v2.mat\")[\"mean_vec\"]\n",
    "std_vec = sio.loadmat(r\"C:\\Users\\User\\OneDrive - mail.tau.ac.il\\Documents\\SA_UI\\not_used\\std_vec_mu_1.6_3components_new_v2.mat\")[\"std_vec\"]\n",
    "hist_space = sio.loadmat(r\"C:\\Users\\User\\OneDrive - mail.tau.ac.il\\Documents\\SA_UI\\not_used\\hist_space_mu_1.6_3components_new_v2.mat\")[\"hist_space\"]\n",
    "x_hist_space = sio.loadmat(r\"C:\\Users\\User\\OneDrive - mail.tau.ac.il\\Documents\\SA_UI\\not_used\\x_hist_space_mu_1.6_3components_new_v2.mat\")[\"x_hist_space\"]\n",
    "x_ticks = sio.loadmat(r\"C:\\Users\\User\\OneDrive - mail.tau.ac.il\\Documents\\SA_UI\\not_used\\x_ticks_mu_1.6_3components_new_v2.mat\")[\"x_ticks\"]\n",
    "y_ticks = sio.loadmat(r\"C:\\Users\\User\\OneDrive - mail.tau.ac.il\\Documents\\SA_UI\\not_used\\y_ticks_mu_1.6_3components_new_v2.mat\")[\"y_ticks\"]\n",
    "path=r\"C:\\Users\\User\\OneDrive - mail.tau.ac.il\\Documents\\SA_UI\\not_used\""
   ],
   "id": "53a1229e762e0b06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hist_space = np.reshape(hist_space,(hist_space.shape[1],1))\n",
    "mean_vec = np.reshape(mean_vec,(mean_vec.shape[1],1))\n",
    "x_hist_space = np.reshape(x_hist_space,(x_hist_space.shape[1],1))\n",
    "y_ticks = np.reshape(y_ticks,(y_ticks.shape[1],1))\n",
    "x_ticks = np.reshape(x_ticks,(x_ticks.shape[1],1))"
   ],
   "id": "f8d01b4b07c20a20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "SLM_tools.cv_bias_correction(tfas_predict_mat_2=tfas_predict_mat_2, tfas_actually_mat_2=tfas_actually_mat_2, hist_space=hist_space, mean_vec=mean_vec, x_hist_space=x_hist_space,x_ticks=x_ticks,y_ticks=y_ticks,save_path=path)",
   "id": "803562acd8b4be2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = np.array([[np.nan,0,1],[1,2,3]])\n",
    "a[np.isnan(a)] = 0"
   ],
   "id": "c0a19365c7ca8057",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "a",
   "id": "edf50b44ced75cbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "78983c5b7e23d373",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
